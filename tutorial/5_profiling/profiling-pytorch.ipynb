{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling with PyTorch\n",
    "In this notebook we will go through profiling your training with PyTorch and Holistic Trace Analysis.\n",
    "\n",
    "## Setting up model and dataset\n",
    "For this example we will use [Tiny ImageNet](https://www.kaggle.com/c/tiny-imagenet/overview) which is similar to ImageNet but lower resolution (64x64) and fewer images (100 k). For this dataset we will use a variant of the ResNet architecture wich is a type of Convolutional Neural Network with residual connections. For the sake of this tutorial you do not need to understand the details about the model or the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datapipe\n",
    "First we construct a utility function to yield datapipes to later use in our DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the HTA model imported.\n",
    "import hta\n",
    "print(\"HTA module imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "from pytorch_dataset import TinyImageNetDataset \n",
    "from torch import nn, optim, profiler\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from hta.trace_analysis import TraceAnalysis  # Import HTA\n",
    "import matplotlib.pyplot as plt\n",
    "# incase we need a high-level API for creating interactive plots using Plotly:\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")",
    "\n",
    "# For performance set precision,\n",
    "# see https://www.c3se.chalmers.se/documentation/applications/pytorch/#performance-and-precision\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TinyImageNet dataset using the custom dataset class\n",
    "path_to_dataset = '/mimer/NOBACKUP/Datasets/tiny-imagenet-200/tiny-imagenet-200.zip'\n",
    "\n",
    "train_dataset = TinyImageNetDataset(path_to_dataset=path_to_dataset, split='train')\n",
    "val_dataset = TinyImageNetDataset(path_to_dataset=path_to_dataset, split='val')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-18\n",
    "pretrained = True\n",
    "model = resnet18(weights=None, num_classes=200)\n",
    "if pretrained:\n",
    "    pretrained_state_dict = resnet18(\n",
    "        pretrained=pretrained,\n",
    "        num_classes=1000,\n",
    "        progress=False,\n",
    "    ).state_dict()\n",
    "    for key in [\"fc.weight\", \"fc.bias\"]:\n",
    "        del pretrained_state_dict[key]\n",
    "    model.load_state_dict(pretrained_state_dict, strict=False)\n",
    "\n",
    "# Optimizer\n",
    "opt = optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "# Other\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "# device = torch.device(\"cuda\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "def train_step(images, labels):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    est = model(images)\n",
    "    loss = loss_func(est, labels)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having taken care of these initialisations we are ready to take a look at profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_dir = './trace_hta'\n",
    "os.makedirs(trace_dir, exist_ok=True)\n",
    "\n",
    "with profiler.profile(\n",
    "    schedule=profiler.schedule(wait=10, warmup=5, active=10, repeat=2),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as prof:\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        loss = train_step(images, labels)\n",
    "\n",
    "        # Step scheduler\n",
    "        prof.step()\n",
    "        print(f\"\\rStep: {step + 1}/50\", end=\"\")\n",
    "        if step >= 49:\n",
    "            break\n",
    "\n",
    "    # Save trace as JSON for HTA with a unique filename using timestamp\n",
    "    timestamp = int(time.time())\n",
    "    trace_file = os.path.join(trace_dir, f'trace_{timestamp}.json')\n",
    "    prof.export_chrome_trace(trace_file)\n",
    "    print(timestamp)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you might get warnings for using step() during wait steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"distributedInfo\" key to the trace file\n",
    "%matplotlib inline\n",
    "\n",
    "with open(trace_file, 'r') as file:\n",
    "    trace_data = json.load(file)\n",
    "\n",
    "if \"distributedInfo\" not in trace_data:\n",
    "    trace_data[\"distributedInfo\"] = {\"rank\": 0}\n",
    "\n",
    "with open(trace_file, 'w') as file:\n",
    "    json.dump(trace_data, file, indent=4)\n",
    "\n",
    "\n",
    "# Debug: Print trace file content\n",
    "print(\"\\nTrace File Content:\")\n",
    "#print(json.dumps(trace_data, indent=4))\n",
    "\n",
    "# Analyze the trace using HTA\n",
    "analyzer = TraceAnalysis(trace_dir=trace_dir)\n",
    "\n",
    "\n",
    "# Get temporal breakdown\n",
    "time_spent_df = analyzer.get_temporal_breakdown(visualize=False) # turn off the visualization to use the matplotlib manually\n",
    "\n",
    "print(\"\\nTemporal Breakdown DataFrame:\")\n",
    "print(time_spent_df.head(2))\n",
    "#plt.savefig(os.path.join(trace_dir, 'temporal_breakdown.png'))\n",
    "print(f\"Visualizations and data saved to {trace_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_spent_df.head())\n",
    "print(time_spent_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average step time\n",
    "total_time = time_spent_df['compute_time(us)'].sum() + time_spent_df['non_compute_time(us)'].sum()\n",
    "average_step_time = total_time / len(time_spent_df)\n",
    "print(f\"\\nAverage Step Time: {average_step_time} us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data to plot\n",
    "categories = ['idle_time(us)', 'compute_time(us)', 'non_compute_time(us)', 'kernel_time(us)', \n",
    "              'idle_time_pctg', 'compute_time_pctg', 'non_compute_time_pctg']\n",
    "# Extract first row (assuming only one rank)\n",
    "values = time_spent_df.iloc[0, 1:].values  \n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(categories, values, color=['blue', 'green', 'red', 'purple'])\n",
    "\n",
    "plt.ylabel(\"Time (us)\")\n",
    "plt.title(\"Temporal Breakdown by Category\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data to plot\n",
    "categories = ['idle_time(us)', 'compute_time(us)', 'non_compute_time(us)', 'kernel_time(us)']\n",
    "values = time_spent_df.iloc[0, 1:5].values  \n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(categories, values, color=['blue', 'green', 'red', 'purple'])\n",
    "\n",
    "plt.ylabel(\"Time (us)\")\n",
    "plt.title(\"Temporal Breakdown by Category\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(time_spent_df['rank'], time_spent_df['compute_time(us)'], label='Compute Time')\n",
    "plt.bar(time_spent_df['rank'], time_spent_df['idle_time(us)'], bottom=time_spent_df['compute_time(us)'], label='Idle Time')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Time (us)')\n",
    "plt.title('Temporal Breakdown')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(trace_dir, 'temporal_breakdown.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.pie(time_spent_df['compute_time_pctg'], labels=time_spent_df['rank'], autopct='%1.1f%%')\n",
    "plt.title('Kernel Type Breakdown')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get idle time breakdown\n",
    "idle_time_df = analyzer.get_idle_time_breakdown(visualize=False)\n",
    "print(\"\\nIdle Time Breakdown DataFrame:\")\n",
    "print(idle_time_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(idle_time_df))  # Check if it's really a DataFrame\n",
    "print(idle_time_df)\n",
    "\n",
    "idle_time_df = idle_time_df[0]\n",
    "\n",
    "print(idle_time_df.head())\n",
    "print(idle_time_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot\n",
    "categories = ['idle_time', 'idle_time_ratio']  \n",
    "values = idle_time_df.iloc[0, 3:].values  \n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(categories, values, color=['blue', 'green'])\n",
    "\n",
    "# Labels and title\n",
    "plt.ylabel(\"Time (us) / Ratio\")\n",
    "plt.title(\"Idle Time and Ratio Breakdown\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the DataFrame inside the tuple\n",
    "#idle_time_df = idle_time_df[0]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(idle_time_df['rank'], idle_time_df['idle_time'], label='idle_time')\n",
    "plt.bar(idle_time_df['rank'], idle_time_df['idle_time_ratio'], bottom=idle_time_df['idle_time_ratio'], label='idle_time_ratio')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Time (us)')\n",
    "plt.title('Idle Time')\n",
    "plt.legend()\n",
    "#plt.savefig(os.path.join(trace_dir, 'idle_time.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.pie(idle_time_df['idle_time'], labels=idle_time_df['rank'], autopct='%1.1f%%')\n",
    "plt.title('Idle Time Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get communication computation overlap\n",
    "overlap_df = analyzer.get_comm_comp_overlap(visualize=False)\n",
    "print(\"\\nCommunication Computation Overlap DataFrame:\")\n",
    "print(overlap_df)\n",
    "# manual Visualizations\n",
    "operations = ['idle_time(us)', 'compute_time(us)', 'non_compute_time(us)', 'kernel_time(us)']\n",
    "time_spent = [time_spent_df[col].sum() for col in operations]  # Sum of each category\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(operations, time_spent, color=['blue', 'green', 'red', 'purple'])\n",
    "plt.title('Temporal Breakdown of Operations')\n",
    "plt.ylabel('Time Spent (us)')\n",
    "plt.xlabel('Operation')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type_metrics_df, kernel_metrics_df = analyzer.get_gpu_kernel_breakdown(num_kernels=5,include_memory_kernels=True,image_renderer=\"notebook\",visualize=False)\n",
    "\n",
    "print(\"\\nKernel Type Metrics DataFrame:\")\n",
    "print(kernel_type_metrics_df)\n",
    "print(\"\\nKernel Metrics DataFrame:\")\n",
    "print(kernel_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incase to check the available renders:\n",
    "import plotly\n",
    "print(plotly.io.renderers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make sure of the data type\n",
    "print(type(kernel_type_metrics_df))  \n",
    "print(kernel_type_metrics_df.head())\n",
    "print(kernel_type_metrics_df.columns)\n",
    "\n",
    "print('*************************')\n",
    "print(type(kernel_metrics_df))  \n",
    "print(kernel_metrics_df.head())\n",
    "print(kernel_metrics_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual Visualizations\n",
    "operations = ['sum', 'percentage']\n",
    "kernel_type_metrics = [kernel_type_metrics_df[col].sum() for col in operations]  # Sum of each category\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(operations, kernel_type_metrics, color=['blue', 'red'])\n",
    "plt.title('Kernel Type Metrics - Sum and Percentage')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Operations')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['sum (us)', 'mean (us)', 'stddev']\n",
    "kernel_metrics = [kernel_metrics_df[metric].sum() for metric in metrics]  \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(metrics, kernel_metrics, color=['blue', 'green', 'red'])\n",
    "plt.title('Kernel Metrics - Sum, Mean, and Stddev')\n",
    "plt.ylabel('Value (us)')\n",
    "plt.xlabel('Metrics')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly explore the JSON trace data \n",
    "trace_dir = './trace_hta'\n",
    "trace_files = [f for f in os.listdir(trace_dir) if f.endswith('.json')]\n",
    "\n",
    "all_trace_data = []\n",
    "\n",
    "for trace_file in trace_files:\n",
    "    with open(os.path.join(trace_dir, trace_file), 'r') as f:\n",
    "        trace_data = json.load(f)\n",
    "        all_trace_data.append(trace_data)\n",
    "\n",
    "# Print keys or inspect the data structure of the first trace file\n",
    "if all_trace_data:\n",
    "    print(\"\\nKeys in the first trace data:\", all_trace_data[0].keys())\n",
    "\n",
    "print(\"\\nProfiling and analysis completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercises\n",
    "1. Use HTA to analyze how the execution time, compute time, and idle time are affected by changing the batch size in your training module\n",
    "2. Run the model with different batch sizes (e.g., 64) and use HTA tool to visualize the impact on the idle time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
